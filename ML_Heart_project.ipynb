{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7ca9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7430d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To load dataset \n",
    "df=pd.read_csv('heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a7906f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many samples\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0d34f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check null value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b1e3c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex           int64\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol          int64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach       int64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope         int64\n",
       "ca            int64\n",
       "thal          int64\n",
       "target        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check data type \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1f58e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "#check basic info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d4bc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how statistical Operation\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f65a7ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEcCAYAAADEEw+QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzlUlEQVR4nO3de5wcVZ338c8XBFQuBhQwXDSBJ+AiCwERUBQFZAV0CeIDggqssAIuKOp6AXW9Lo+IoosuwgZF0eWqoESMYmQRdl0CCfe7hIsSiKAstxUFkvk+f5zTpDL0zFRVV8/0dP/evuo1XdVVp88M8fSpU+f8frJNCCGE/rfSRFcghBDC+IgGP4QQBkQ0+CGEMCCiwQ8hhAERDX4IIQyIaPBDCGFAdK3Bl7SHpDskLZJ0bLc+J4QQQjldafAlrQycAuwJbAEcKGmLbnxWCCFMpLE6t5JeIelKSU9J+kiZayWtI2mepDvzz7WbqGu3evjbA4ts3237aeBcYFaXPiuEECZEyc7t/wAfAL5S4dpjgUttzwAuzfsd61aDvyFwX2F/cT4WQgj9ZMzOre2HbC8Anqlw7SzgzPz6TGCfJirbrQZfbY5FDIcQQr/ppHM72rXr214CkH+u12E9AXheE4W0sRjYuLC/EfBA8QRJhwOHAxw3ZetX7bv6tC5VJYTQT7Zb/ON2HcpKnnnoztId0FXX3+wIcluVzbY9O7/upHM77h3jbjX4C4AZkqYD9wMHAO8snpD/YLMBFm60T/T+Qwjjx0PlTy20VW2M2bkdxWjXPihpqu0lkqYCD5Wu8Ci6MqRjeylwNHAJcBtwvu1buvFZIYRQ2dBQ+W10z3ZuJa1K6tzOKVmL0a6dAxySXx8CXFTp9xtBt3r42J4LzO1W+SGEUJcr9PBHL8dLJbU6tysDZ9i+RdKR+f3TJL0UWAisBQxJ+iCwhe3H212biz4BOF/SYcDvgP2aqK96IR5+DOmEEMpqYgz/6cU3lR/D3+ivO/68XtG1Hn4IIfSshnr4k01HY/iSzpD0kKSbC8c+K+l+Sdfnba/OqxlCCA1a9kz5rY90+tD2u8AebY5/zfbMvMU4fgihtzT30HZS6WhIx/YVkqY1VJcQQhgXTT20nWy6tdL2aEk35iGfRoL+hBBCYwa0h9+NBv9UYFNgJrAEOKkLnxFCCPV5qPzWRxpv8G0/aHuZ0z3T6aQAQc8h6XBJCyUtvPBP9zZdjRBCGNnQsvJbH2l8WmZrOXDefRtwc7vzIrRCCGHCLFs60TWYEB01+JLOAd4IvETSYuAzwBslzSQFAboXOKKzKoYQQsP6bKimrE5n6RzY5vC3OykzhBC6rs8expYVK21DCAPH7q+x+bKiwQ8hDJ4Y0qlG0vOBK4DVcjk/tP0ZSesA5wHTSGP4+9t+pPOqhhBCQwb0oW0n0zKfAna1vTVpzv0eknakS8l3QwihMQM6LbN2g+/kf/PuKnkzXUq+G0IIjYmFV9VJWlnS9aT0W/NsX0WXku+GEEJjIrRCdXlF7UxSLsbtJW1Z9tpYaRtCmDDRw6/P9qPAr0ihkh/MSXcZLfmu7dm2t7O93b6rT2uiGiGEUE708KuRtK6kKfn1C4A3AbfTpeS7IYTQFC97pvQ2Fkl7SLpD0iJJz5mkouTr+f0bJW2bj29eSBR1vaTHc77briWS6mQe/lTgTEkrk744zrd9saQr6ULy3RBCaExDPffc/p0C7A4sBhZImmP71sJpewIz8rYDKaLwDrbvIM1wbJVzP/CjwnVfs/2VRiqa1W7wbd8IbNPm+MPAbp1UKoQQuqq5sfntgUW27waQdC5ppmKxwZ8FfM+2gfmSpgwLMgmpzbzL9m+bqlg73UqAEkIIvau5MfwNgfsK+4vzsarnHACcM+xY44mkOm7w89TM6yRdnPcjiXkIobdVmKVTnFGYt8MLJald6cP2Rz1H0qrA3sAPCu93JZFUE7F0jgFuA9YqHGt87CmEEBpTIbRCMXdHG4uBjQv7GwEPVDxnT+Ba2w8WPvPZ15JOBy4uXeFRdLrwaiPgLcC3mqhMCCGMi+aGdBYAMyRNzz31A0gzFYvmAAfn2To7Ao8NG78/kGHDOa2p7dmIiaSq6rSH/y/Ax4A1hx0/WtLBwELgHyN4WgihpzQ0S8f2UklHA5cAKwNn2L5F0pH5/dOAucBewCLgSeA9reslvZA0w2d4oqgTu5FIqpNomW8FHrJ9jaQ3Ft46FfgCqaJfII09HdpBHUMIoVkNrqC1PZfUqBePnVZ4beCoEa59Enhxm+MHNVbBgk6GdHYC9pZ0L3AusKukf48k5iGEnhcrbauxfZztjWxPI41b/Yftd5cde4rQCiGECTOgsXS6kfGqK2NPIYTQmAFNgNJIg2/7V6TgaV0bewohhMb02VBNWZHTNoQweKLBDyGEAeHhi2EHQ6cLr6ZI+qGk2yXdJuk1ktaRNE/SnflnIzEgQgihMTFLp5aTgZ/bfgWwNSnEQiQxDyH0tgFt8DtZeLUWsDPwdwC2nwaeljQLeGM+7UzSw9yPd1LJEEJo1IDO0umkh78J8AfgOzla5rckrU4kMQ8h9Dq7/NZHOmnwnwdsC5xqexvgT8TwTQhhMhjQIZ1OGvzFwGLbV+X9H5K+AEolMY/QCiGECRMNfjW2fw/cJ2nzfGg3UlqvUknMI7RCCGHCRGiFWt4PnJXjQN9NCvu5EpHEPITQw7x02URXYUJ01ODbvh7Yrs1bkcQ8hNC7+qznXlastA0hDJ6h/pp9U1Y0+CGEwdNnD2PL6mTh1ebAeYVDmwCfBqYA7yXN0Qf4RM4IE0IIvWFAG/xOZuncYXum7ZnAq0i5Gn+U3/5a671o7EMIPafBhVeS9pB0h6RFkp6zFiknL/96fv9GSdsW3rtX0k2Srpe0sHC8KzHJOo2l07IbcJft3zZUXgghdM/SZeW3UUhaGTgF2BPYAjhQ0hbDTtsTmJG3w0l5v4t2yZ3j4gSYrsQka6rBPwA4p7B/dP4mOyOiZYYQek5z8/C3BxbZvjvHEzsXmDXsnFnA95zMB6YMSwXbzixSLDLyz30q/X4j6LjBz3Pw9wZ+kA+dCmwKzASWACd1+hkhhNCoIZffRrchcF9hf3E+VvYcA7+QdI2kwwvndCUmWRM9/D2Ba20/CGD7QdvLbA8Bp5O+AZ8jQiuEECaKh4ZKb8W2Km/Fhlntih+2P9o5O9neltSOHiVp5wZ+vRE1MS3zQArDOZKmtr6ZgLcBN7e7yPZsYDbAwo32GcxJsSGEiVFhHn6xrWpjMbBxYX8j4IGy59hu/XxI0o9IHeQryDHJbC8ZLSZZVZ1mvHohsDtwYeHwifmp843ALsCHOvmMEEJoXHNj+AuAGZKm5+HtA0jxxIrmAAfn2To7Ao/lhnx1SWsC5NDyf8PyDnKpmGRVdRpa4UngxcOOHdRRjUIIodsaiqVje6mko4FLgJWBM2zfIunI/P5pwFxgL2ARafr6e/Ll6wM/kgSpLT7b9s/zeyfQhZhksdI2hDB4GgytkNcazR127LTCawNHtbnublJq2HZlPkwXYpJFgx9CGDwDGjyt0zH8YyTdLOkWSR/Mx7qyQiyEEBrT3LTMSaV2gy9pS1LMnO1JtyVvlTSDLq0QCyGEplSZltlPOunh/xUw3/aTtpcCl5OmYXZlhVgIITRm6VD5rY900uDfDOws6cV5euZepLmmXVkhFkIIjYkUh9XYvk3Sl4B5wP8CNwBLm6pYCCF0TZ+NzZfV0UNb29+2va3tnYH/Ae4krxCDtOqWEVaIRWiFEMJE8ZBLb/2k01k66+WfLwP2JYVYKLVCzPZs29vZ3m7f1ad1Uo0QQqhmQGfpdDoP/wJJLwaeAY6y/YikrqwQCyGExvTZ7JuyOg2t8Po2x7qyQiyEEBrTZ7NvyoqVtiGEgeMSqQv7UTT4IYTB02dj82WN+dA2pyl8SNLNhWNtwydImibpzzkh7/WSThu55BBCmCAD+tC2zCyd7wJ7DDs2WviEu3JC3pm2j2ymmiGE0JyYljkC21eQ5tgXRfiEEMLkFT38SkYLnzBd0nWSLpf0nFk8IYQw0bzUpbd+0kQS86IlwMtsbwN8GDhb0lrtToyVtiGECRM9/Erahk+w/VSeh4/ta4C7gM3aFRArbUMIE2aowtZH6jb4bcMnSFpX0sr59SbADODuTisZQghNavKhraQ9JN0haZGk5+T/yMnLv57fv1HStvn4xpIuk3RbTiJ1TOGaz0q6vzDjca8mfu8x5+FLOgd4I/ASSYuBzzBygt2dgc9LWgosA460PfyBbwghTKyGeu65g3sKsDuwGFggaY7tWwun7Unq/M4AdgBOzT+XAv9o+1pJawLXSJpXuPZrtr/STE2TMRt82weO8NZzwifYvgC4oNNKhRBCNzX4MHZ7YFFOSI6kc0mzGIsN/izgezmZ+XxJUyRNzRNeWpNfnpB0G7DhsGsb1fRD2xBC6HkN5j/ZELivsL84H6t0jqRpwDbAVYXDR+choDOayg1ed6XtlyXdnivzI0lTCu8dl8eq7pD05iYqGUIIjarw0LY4ozBvhxdKUpvSh98+jHqOpDVIIyMftP14PnwqsCkwk3QXcFK1X7C9uitt5wFb2t4K+A1wHICkLYADgFfma77ZeogbQgi9okoPvzijMG+zC0UtJqV2bdkIeGDYx414jqRVSI39WbYvfLZ+9oO2l9keAk4nDR11rNZKW9u/yInLAebnXwDSWNW5eXrmPcCipioaQgiNaW5a5gJghqTpklYldXjnDDtnDnBwnq2zI/CY7SWSBHwbuM32V4sXtKa9Z28j5RDvWBPRMg8FzsuvNyR9AbS0G88KIYQJ1VRucttLJR0NXAKsDJxh+xZJR+b3TwPmAnuROsBPAu/Jl+8EHATcJOn6fOwTtucCJ0qaSRr6uRc4oon6dtTgS/okaWrRWa1DbU7rr6VqIYRJb2jp2OeUlRvoucOOnVZ4beCoNtf9F+3bTGwf1FwNl6s9S0fSIcBbgXd5eTaBMuNZresjtEIIYWJY5bc+UqvBl7QH8HFgb9tPFt6aAxwgaTVJ00kLDa5uV0aEVgghTJQGp2VOKnVX2h4HrAbMS88dmG/7yDx2dT5p4cBSUmLzZd2qfAgh1OGh/uq5l1V3pe23Rzn/eOD4TioVQgjd1G8997Iip20IYeAMLYsefgghDIRBHdKpG1rhCzmswvWSfiFpg3w8kpiHEHqeXX7rJ3VDK3zZ9la2ZwIXA58uvBdJzEMIPc1DKr31kzIPba/IkdyKxx4v7K5OLK4KIUwi/daQl1V7DF/S8cDBwGPALoW3pku6Dngc+JTt/+ysiiGE0Kx+G6opq/ZKW9uftL0xKazC0flw6STmIYQwUYaWrVR66ydN/DZnA2+HaknMI7RCCGGiDOpK27qhFWYUdvcGbs/HSycxj9AKIYSJMmSV3vpJ3dAKe0nanBQt+rdAazZOJDEPIfQ891lDXlajoRUiiXkIYTKIWTohhDAgBnWWTjT4IYSBs6zPZt+UVTe0wmcl3V8IobBX4b3jJC2SdIekN3er4iGEUJet0ls/qRtaAeBrhRAKcwEkbUFK4vvKfM03W7N2QgihV0QsnRHYvgIoO9NmFnBuno9/Dylp7/Yd1C+EEBrX5LRMSXvkEY1Fko5t874kfT2/f6Okbce6VtI6kuZJujP/XLuJ37uTgayjc+XPKFRmQ+C+wjmL87EQQugZTQ3p5BGMU4A9gS2AA/NIR9GepDVJM4DDgVNLXHsscKntGcCleb9jdRv8U4FNgZmkcAon5ePt/jp9dlMUQpjslg2p9DaG7YFFtu+2/TRwLmmko2gW8D0n84EpkqaOce0s4Mz8+kxgn45/aWo2+LYftL3M9hBwOsuHbRYDGxdO3Qh4oF0ZEVohhDBRqvTwi21V3g4vFFVmVGOkc0a7dn3bS1JdvQRYr/Pfuua0TElTW5UB3ga0ZvDMIQVM+yqwAekW5up2ZdieDcwGWLjRPnEXEEIYN1VCJhTbqjbKjGqMdM64j4jUDa3wRkkzc+XuBY4AsH2LpPOBW4GlwFG2l3Wl5iGEUFODrWqZUY2Rzll1lGsfbHWs8/DPQ01UttHQCvn844HjO6lUCCF0U4NB0RYAMyRNB+4nTUt/57Bz5pAmuZwL7AA8lhvyP4xy7RzgEOCE/POiJiobK21DCAOnqQVVtpdKOhq4BFgZOCOPdByZ3z8NmAvsRZqm/iTwntGuzUWfAJwv6TDgd8B+TdQ3GvwQwsBZ1nb4vJ688HTusGOnFV4bOKrstfn4w8BujVUyqxVaIR9/f14wcIukE/OxaZL+XAi5cFr7UkMIYeIMufzWT8r08L8L/CvwvdYBSbuQ5oluZfspScUpQ3fZntlkJUMIoUlDDfbwJ5MyD22vkDRt2OH3ASfYfiqf08gT5BBCGA8e0Aa/7krbzYDXS7pK0uWSXl14b7qk6/Lx1zdQxxBCaNRQha2f1G3wnwesDewIfJT0NFmkMAsvs70N8GHSIqy12hUQK21DCBPFqPTWT+o2+IuBC3NsiKtJX4QvyVEyHwawfQ1wF+lu4DkiiXkIYaIsrbD1k7oN/o+BXQEkbUZaMfZHSeu24t9L2oQUWuHuBuoZQgiNGdQeft3QCmcAZ+Spmk8Dh9i2pJ2Bz0taCiwDjrRdNpZ+CCGMiwHNYV47tALAu9ucewFwQaeVCiGEboppmSGEMCD6bD1VaXWTmM+UND+vpl0oafvCe5HEPITQ05ZKpbd+UjeJ+YnA5/KK2k/n/UhiHkKYFFxh6yd1k5gbaM2vfxHLYzhHEvMQQs8b1IVXdcfwPwhcIukrpC+N1+bjGwLzC+dFEvMQQs8Z1Fk6defhvw/4kO2NgQ+xPCFKJDEPIfS8IVR66yd1G/xDgAvz6x8QScxDCJNIjOFX8wDwhvx6V+DO/HoOcICk1XLarlGTmEdohRDCRFiq8ls/qbvS9r3AyZKeB/wFOBwiiXkIYXLot557WZ2stH3VCOdHEvMQQk8br4e2ktYBzgOmAfcC+9t+pM15ewAnk3Lbfsv2Cfn4l4G/JYWwuQt4j+1Hc46S24A7chHzbR85Vn3qDumEEMKkNY7TMo8FLrU9A7g0768gr1U6BdgT2AI4MK9pApgHbGl7K+A3wHGFS++yPTNvYzb2EA1+CGEAjWODPws4M78+E9inzTnbA4ts3237aeDcfB22f2G7FaV5PmkiTG11QytsLelKSTdJ+kkryUkkMQ8hTAZW+a1D69teApB/rtfmnA2B+wr7I61fOhT4WWG/cnbBWknMgW8BH7F9uaRDSVmv/im/F0nMQwg9rUpiE0mHkyemZLNtzy68/0vgpW0u/WTZj2hzbIXnypI+Sar2WflQK7vgw5JeBfxY0ittPz7aB9VNYr45cEV+PQ+4hOUNfggh9LQqs3Ry4z57lPffNNJ7kh6UNNX2EklTgYfanDbq+iVJhwBvBXaz7fyZTwFP5dfXSGplF1w42u9Sdwz/ZmDv/Hq/YZWNJOYhhJ42pPJbh+aQFqqSf17U5pwFwAxJ0yWtSgpAOQeenb3zcWBv20+2LqibXbBug38ocJSka4A1SVOGoEIS8xBCmCjj+ND2BGB3SXcCu+d9JG0gaS5Afih7NGmk5DbgfNu35Ov/ldTGzhv2XHRn4EZJNwA/pGR2wVrB02zfDvxNrvhmwFvy8dK3GcVxseOmbE2stg0hjJfxioJp+2FgtzbHHwD2KuzPBea2Oe//jFBureyCtXr4ktbLP1cCPgWclvdL32ZEaIUQwkRZpvJbP6kbWmENSUflUy4EvpNfRxLzEELP67c492V1Elrh5DbnRhLzEELPi1g6IYQwIIYGtMmPBj+EMHAGdUinTGiFjSVdJuk2SbdIOiYf3y/vD0nabtg1x0laJOkOSW/uVuVDCKGOQU2AUqaHvxT4R9vXSloTuEbSPNLiq32BfyuenKO8HQC8EtgA+KWkzSIufgihV/RbYpOyyjy0XUJaUIXtJyTdBmxoex6A9Jy/3Czg3Dwn/x5Ji0jR4K5ssuIhhFDXoI7hV5qHn2PqbANcNcppZSO/hRDChIghnTFIWoM05fKDY0RkGzPyWwghTKR4aDsKSauQGvuzbF84xumjRn4rlHm4pIWSFl74p3tLVjeEEDo3hEtv/aTMLB0B3wZus/3VEmXOAQ6QtJqk6aTwClcPPylCK4QQJsqyCls/KTOksxNwEHCTpOvzsU8AqwHfANYFfirpettvtn2LpPOBW0kzfI6KGTohhF7Sbz33ssrM0vkv2o/LA/xohGuOB47voF4hhNA1g9ncx0rbEMIAGtSHttHghxAGjge0j99JaIUvS7pd0o2SfiRpSj4+TdKfc3aWYoaWEELoCeOY8aqndBJaYR5wnO2lkr4EHEfKvQhwl+2ZXalxCCF0aFn08NuzvcT2tfn1E6Scixva/kXOxQgwnzTfPoQQet54zcOXtI6keZLuzD/XHuG8PXKwyUWSji0c/6yk+wsjJnsV3qscpLKp0AqHAj8r7E+XdJ2kyyW9vspnhBBCt43jkM6xwKW2ZwCX5v0V5LSwpwB7AlsAB+YglC1fsz0zb3PzNcUglXsA32yllx1N6QZ/pNAKkj5JGvY5Kx9aArzM9jbAh4GzJa3VprxYaRtCmBCu8L8OzQLOzK/PBPZpc872wCLbd9t+Gjg3XzdWuefafsr2PUArSOWoOgqtIOkQ4K3Au2wbIFfg4fz6GuAuYLPhZcZK2xDCRBnHHv76OeJwK/Lwem3OGSvg5NF5cswZhSGhWkEqa4dWkLQH6SHt3rafLBxft3VrIWkTUmiFu8f6nBBCGC9VevjF0Yi8HV4sS9IvJd3cZhurl/5sEW2rmJwKbArMJI2enFTimhF1Elrh66TwCvNyTPz5to8EdgY+L2kpKRTFkbb/p8TnhBDCuFjq8kM1tmcDs0d5/00jvSfpQUlTbS+RNBV4qM1pIwactP1goazTgYvHumY0nYRWmDvC+ReQhn9CCKEnjeOkzDnAIcAJ+edFbc5ZAMzIwSbvJz2MfSdA68sin/c2UqbBVrlnS/oqKbNg2yCVw8VK2xDCwBnH4GknAOdLOgz4HbAfgKQNgG/Z3iuvZToauARYGTjD9i35+hMlzSR9R90LHAFQN0jlmA2+pI2B7wEvJT3DmG375ML7HwG+DKxr+4/52HHAYaQhnQ/YvmSszwkhhPEyXqEV8gSW3docfwDYq7A/lzajJrYPGqXsykEqa6+0tX1r/jLYnfTNBUQS8xBC7+u3kAll1V5pm9/+GvAxVhwSqzU/NIQQxssyhkpv/aT2SltJewP3275h2GmRxDyE0NMieNoYiittScM8nwT+pt2pbY4NZqSiEEJPcoVpmf2k7krbTYHpwA2S7iXNAb1W0kuJJOYhhB4XScxH0G6lre2bbK9ne5rtaaRGflvbvyeSmIcQelwM6Yys7UrbVtS24SKJeQih1w1qxqtOk5i3zpk2bD+SmIcQetYy91vfvZxYaRtCGDiD2dxHgx9CGECDOqTTSRLztqm3Iol5CKHXDeosnU6SmENKvfWVNtdEEvMQQs8a1Hn4ZR7aLiEF3sf2E5KKoRVCCGHS6beee1mdJjFvl3oLIol5CKGHLfNQ6a2fdJLEfKTUW6WSmIcQwkRxha2f1E5ibvtB28tsDwGnkyNilk1iHqEVQggTZVAf2naSxHxq4bRnU2+VTWIeoRVCCBNlUBv8TpKYH9gu9RaRxDyE0ONils4IIol5CKHfjFdiE0nrAOcB00gd4/1tP9LmvD2Ak0k5bb9l+4R8/Dxg83zaFOBR2zPzBJrbgDvye/NtHzlWfWKlbQhh4IxjD/9Y4FLbJ0g6Nu9/vHhCHgI/hZQudjGwQNIc27fafkfhvJOAxwqXVl7vVGlaZggh9INxHMOfBZyZX58J7NPmnO2BRbbvtv00cG6+7ln5Wer+wDmdVKaT0ArnFcIn3FsY30fScZIWSbpD0ps7qWAIITTNdumtQ+vnxautRazrtTmnTFrY1wMP2r6zcKzyeqfaoRVGutWQtAVwAPBKYAPgl5I2i5j4IYReUaXnLulw4PDCodm2Zxfe/yXw0jaXfrLsR7Q5NryCB7Ji77613ulhSa8CfizplXmN1Ig6Ca1wK6xwq7FrvmQWcK7tp4B7JC0i3bJcOdZnhRDCeKgSLTM37rNHef9NI70n6UFJU20vyVPZH2pz2qhpYSU9D9gXeFXhM58Cnsqvr5HUWu+0cLTfpdPQCvDcW40ytychhDBhxjG0whzgkPz6EOCiNucsAGZImi5pVdIIyZzC+28Cbre9uHWg7Hqn4UrP0mkTWqFl+K1GmduTEEKYMEPjN0vnBOB8SYcBvwP2A5C0AWn65V62l0o6GriENC3zDNu3FMo4gOc+rK213qlUg98utEI+/pxbDca4PSlc++y42HFTtiZW24YQxst4JUDJYWZ2a3P8AWCvwv5cRl7b9HdtjtVa71Q7tEL2nFsN0q3IAZJWkzSddKtxdZsKR2iFEMKEGLJLb/2kdmiF/I30nFsN27dIOp/0UHcpcFTM0Akh9JJBTXHYSWiFtrca+fjxwPEd1SyEELqk33ruZUVohRDCwBka0EGHaPBDCAOn38Iel9VJaIWZkubn0AoLJW2fj0+T9OdC2IXTuv1LhBBCFeMYWqGn1A6tAJwIfM72zyTtlfffmK+pHMUthBDGy6D28DsJrWCglav2RbSZax9CCL2o33ruZVUawx8WWuGDwCWSvkIaGnpt4dTpkq4DHgc+Zfs/G6ltCCE0oIGQCZNS6Vg6bUIrvA/4kO2NgQ+RFmfB8ihu2wAfBs6WtFab8iKJeQhhQgzqGL7K/EI5tMLFwCWt1baSHgOm2HZejfuY7XYN+6+Aj9geMYrbwo326a+/agiha7Zb/OO264KqWPdFm5duc/7w2B0df16v6CS0wgPAG/LrXYE78/m1oriFEMJ4GdQefu3QCsB7gZNzALW/sDxBQK0obiGEMF5ipe0IRgutwIpRMlvn14riFkII46Xfeu5lxUrbEMLAiVk6I5D0fElXS7ohr7T9XD6+jqR5ku7MP9cuXBNJzEMIPWtQwyOXmZb5FLCr7a2BmcAeknYEjgUutT0DuDTvD09ivgfwzdZD3BBC6AWu8L9+MmaD7+R/8+4qeTMpWfmZ+fiZwD759bNJzG3fA7SSmIcQQk+IHv4oJK2cZ+g8BMyzfRWwfg670Aq/sF4+PZKYhxB62nhNyxxt6HvYeWdIekjSzWWvrzN0XqrBt70sB0PbCNhe0pajnB5JzEMIPW0ch3TaDn238V3SEHip6+sOnZcOrQBg+1HgV/kDHpQ0NX/4VFLvHyokMY/QCiGEiTA0NFR669BIQ98rsH0F0G69UqND52Vm6awraUp+/QJy4nJSsvJD8mmHABfl15HEPITQ01xh69BIQ9+dXl9v6LzE+NVWwHXAjcDNwKfz8ReTbjHuzD/XKVzzSeAu4A5gzyrjZWPU5fAoa2LK6uW6RVn9UVY3ymuqTsDCwnb4sPd/mdvG4dss4NFh5z4yyudMA24edqzt9cApwLsLx78NvH3M32Wi/5gV//ALo6yJKauX6xZl9UdZ3Shvorfc6Z2aX08F7hjl3HYNftvrgeOA4wrnXQK8Zqz6VBrDDyGEUMlIQ9+dXl9q6Hy4aPBDCKF7TgB2l3QnsHveR9IGkua2TpJ0DnAlsLmkxZIOG+1627cA5wO3Aj8HjrK9bKzKTLZYOrOjrAkrq+nyoqwoazzKm1C2HwZ2a3P8AWCvwv6BVa7P7x0PHF+lPqUSoIQQQpj8YkgnhBAGRDT4IYQwIKLBDyGEATFpGnxJqzdQxmHD9leW9JkOyltV0laS/lrSqp3WL5e5tqStmiirU5J2av3dJb1b0lclvbyD8rZts22a02T2BUnrtDk2fSLqMhm0+9vE36t7ev6hraTXAt8C1rD9MklbA0fY/ocaZZ0NTAEOI60U/g5wue2P1CjrLcBppBXFAqbnev2sRlm/AvYmzZq6HvhDrteHK5RxE+1XgosU5bryl4ikG4GtSautv09azbev7TeMeuHI5c0HtiWt2hawZX79YlLu419UKOu1pIUqz35Z2P5ejTq1+7s9RlpR+c95lkSV8n5NWl3+eN7fAjjf9mgBB0cqazPgVNLy+i1zR2Bv2/9co6x1gY8DWwDPbx23vWuFMvYd7X3bF9ao17W2tx127Brbz0mfGjo3GXpWXwPeTFpogO0bJO1cpyDb75T0DuAm4EngQNu/rlmvk4BdbC8CkLQp8FOgcoMPvMj245L+HviO7c/kxraKt9b43LEstW1Js4CTbX9b0iFjXjWye4HD8hziVmP4UeALwIVAqQZf0veBTUlfjq25xwYqN/ik/17LgLPz/gH55+OkCIZ/W7G8/wf8JHcINs91eleNegGcTvr7/BuA7Rtzp6Vygw+cBZwHvAU4krSI5w8Vyxjtb2HSf8NSJL2CFOnxRcO+SNai8IUUmjUZGnxs3yetEHV5zAUG7UiaARxDSrL+V8BBkq6z/WSN4h5qNfbZ3SyPGFrV83LE0f1JcYgqs/3b1mtJ6wOvzrtX265bryckHQccBLw+h19dpWZZAK9oNfYAtm+VtI3tu4f99x3LdsAWbub2dCfbOxX2b5L0a9s7SXp31cJs/1TSKqQvrzWBfWzfWbNuL7R99bC/zdKaZb04f2EfY/ty4HJJl1cpwPZ7an52O5uTOilTWPGL5AngvQ1+TiiYDA3+ffn23Xmc/APAbTXL+glwtO1fKv2/6MPAAlJPo6pb8kq580m9m/2ABa3eSsXb28+TYmH82vYCSZuQgtJVJml/4MukMNYCviHpo7Z/WKO4dwDvBA61/XtJL8tl13WHpFOBcwvl/0bSasAzFcq5GXgpsKSDurSsIWkHp6Q+SNoeWCO/V7pxlfQNVhwaWovUCXi/JGx/oEbd/pjvHJ0/4/9S/3du/X2X5LuPB0ihy2vJZbySFYeHPl/2etsXARdJeo3tK+vWI1QzGcbwXwKcTArLLFLP6ZiqY6u5rLVaY6uFYzPq9MAkfafNYbN8zPzQqmU2QdINwO6tXn0eu/2lU07iOuW9lBRn28AC27/voG4vAP4BeB3p7/RfwDeBv5B6s/87yuVI+kmux5qk/MpXk3IuA2B77xp1ejVwBqmRF2ko5++BW4C32D6/ZDmjDnXZPnO090cocxPSytPXAo8A9wDvKt7NVSjrrcB/knJVfIP0hfRZ2z+pUdZpwAuBXUjP1/4v6U7ysFEvbF9WY88pQgmdRoObTBuwPunB48/z/hakMeU6ZZ0JTCnsrw2cUbOsTUh3H38gDQtdBEyvWdZNw/ZXGn6sQll/D/yONJZ9JmkM/tAO/v6rAysX9lcmNfRlr3/DaFuH/zZeVPzv2Utb/rut2WEZw/+9rtPBv9cbh/1cA/hFzbIuJ3Uoriscu7lOWbGNvfX8kI6kr7c5/BgpjGrVyHPfJc3MaY2T/4b0IOvbNaq2lVMGMABsPyJpmxrlQHpgeArwtrx/AGnYY4caZf1c0iXAOXn/HcDcUc4fzUeBbZzvpiS9GPhvUo+4jktJd2qtnvwLSHdsry1zsdPYc2va3hLbf8n7LyB9mVeWh5PeTp7x0xovd4XhiWHlzQC+yHNnw2xSo6wXA58h3RFZ0n8Bn3eNu1ue++/1fzr49/rn/PNJSRsAD5NmqdXR5HOKMIbJMA//+aTb9zvzthWpd3KYpH+pWNZLnG7RhwBsL6XmA2BgJa2YUHgd6j8Tke3v216at3+nZrId2x8lDQNsRZpSOdv2x2vWazHpIVrLE6yYZaeq57swbJNfv7BGOT8g/zfMluVjdVxESlSxFPhTYavrO6QhiqWkIY/vkaa01nEu6a7v7aRhkz+QOih1NPnv9WKlLHhfBq4l3fmdO9oFo2jyOUUYQ8/38IH/A+yaG2fyQ79fkEKF3lSxrD/lXlPrH9eOpLuFOk4C/lvSD3N5+1Mxcl3BZZKOJf2fxqRe+U9bi3hst8t1OSLbF5BmItUiqTX//37gKkkX5XrNokTM7VH8SdK2tq/Nn/MqlvcWq3ie7adbO7afVv2FbxvZbpc8uq4X2L5UkpzG2j8r6T9JPfWq1rH9hcL+P0vap2a9Gvv3WqjTBZIuJn2R1/3/0VGkDsorJN1Pek5ReXZUKGcyNPgbksYwW/+gVgc2sL1M0lMjX9bWh0nz+TfNC2TWJfWcKrP9PUkLgV1JD/v2tX1rnbJIDTzAEcOOH0r6P2fp4YA8S+hLpNyXYvlD5LUq1GcbUlLkvwX+pXC86hDacB8EfiCpldR+Kst/9yr+IGlv23MA8jqBP9as039L+mvbVTsPI/mLpJWAOyUdTfrSrJrHtOUySQeQZoJB+rf60zoFNfzv9TkL3/JMpMrrIGzfDbxJaUX3SrafGOuaUN9kmKVzGPAplk8z3Jm0uOUc0iyDj1Yoaz/S9MeNSbfJOwD/1Opx9gNJi4C/tV136iqSbgX2JD1IfuPw96vecQwrexXSHGwBt9uuMh2zVcampIVEG+Ry7gMO9orrIsqWdSvpLvIe0oyf2iuTc3mvJk0bnkJaULYW8GXb82uU9QSpg9MavlqJ5cNNVb/EGzPSwjfXmHpauJssegy4xvb1desY2uv5Bh9SdhjS4p/bSf8HWGz7ihrl3Gh7K0mvI31pnAR8wnadh6ONkfR8lk9XNGn63Gmth5IVy/q1V1xIVKc+HwDeR3oQ90DxLdL/sSs/gMzlvpB0l/Vy2+/NDzg3t31xzfLWIP0brt0r1AixgVxj6uOwcle33cmzgJ4l6TYaWvimtHJ4O1LnAtJK4AXAK4Af2D6x088Iy/V8g68UbuAY0iKR64EdgStdIQZIoazrbG8j6YukqYpnt441Wunq9Tqf9ED03/OhA4G1be9XoYzW8vQ3kBYl/ZgV56jXiXNyqu33Vb1ulPLOA64h9ca3zLNrrrQ9s0ZZHS38aVPeesPK+l3Ncl5DmvXVceynXN7epLtagF/V/XJskqQfAB+w3fHD1Tyj7O2th/n5S/yHpBlr19jeotPPCMtNhjH8Y0hhAubb3kUpBsfnapZ1v6R/I00N/FKektcLM5U294oLoy7LC6iqaC1PNylO0N8U3qsU5+TZixps7LNNbb9D0oG5/D9L1WIqwMgLf+pUKDeoJ5GGhx4CXk4akqmz+hrSM49GYj9JOoH0b/+sfOgYSa+zfWzNunVk2MK3WyV1vPANeBnwdGH/GdId4J9rPKMLY5gMDf5fbP9FEpJWs327pM1rlrU/sAfwFduPKsWvKf0MoIuuk7Rja5xX0g5ApaBuznFOJJ1JWon8aN5fm9Sg9YKnc6++NUtqUwoNRgWvzUNzN9r+nKSTqPGFln2BdNf4y3z3twvpDqs2NxT7iZTzdKbtIXj2v+11wIQ0+MBXSMN6XwL2KRxvHavjbGB+ngkGqeNyTn6IW/uhcmhvMjT4i/Oc3x8D8yQ9worjyqU5BUm7sLC/hAmc86vloXlXAQ6W9Lu8/3Lq/2NvckFY0z4L/BzYWNJZwE5AnYBcTS78ecb2w5JWkrSS7csk1W28oNnYT5Ae/rYekr+og3I6Vlj4tkrrdUv+Iq8k3919l7QwsBVu40jbC/MpdaOMhhH0fINvu7X69LOSLiP9o//5BFapSd0IabySpLVtPwIdL7BplO1fSLqG1KMW6U6kznTK4Qt/TBraqePRPG58BXCWpIfobKXnkaTYTxuSpmReQpprXscXSXd/l7F8htpxHdStI5LeR5pcsIlWDN+9JhXvSCE9/Zf0Y6fY99c0VM0wip5/aDsIJH3f9kFjHStZ1sGkRmGFBTa26672bIykS23vNtaximWuRgcLf/LQwV9IDeq7SB2Ks1wvfEHj8rDjq0n1u8odBK9roC4vIsWM+iIrDis9UXeqrqRTgO/aXtBAFcMYosHvARqW9Ucp5d+NdWcoKCUWaS2wubSTBTZNyNNOXwhcRprX3xrgXgv4me2/KllONzIubTH87yPpjbZ/VbWsfO0mpB7+jqQv3CuBD+UFRmXL2Ha09/ts3citwGbAb0lrDDpaBxFG1xO3+oNKKbnIJ4AXSGqFbRZp1sLsuuXmBqyXHngdQVpluwHp1r3V4D9OChpXVmMZlwrOzwuJTiRNyzyRNC/8NTXKgvaB8M6hWiC8dg/Ziz2zylOSe9ieE12BQRI9/B4g6Yu2J2xsdrxIer/tb0x0PYrykM6XgFeRxqLPAr7UmhlTo7yrhi/kkzTf9o41ytqfFMr7cUn/RMoH/IV+6uG3NLUOIoyuF+agh/QQcnUASe+W9NWRVoBOcr+XtCaApE9JunCs4YuRSHqLpI9J+nRrq1mnZ0izfl5AanDuqdvYZ5dJOlbSNEkvl/QxciC8/AC9ik/lxv51pGCB3yVF4uwbkvaWdCcptMXlpMibdfJChxKiwe8Np5KmGG4NfIw0nlknIXev+yfbT+QG7M2kpByVG7C88OodwPtJw0P7kaay1rGA1OBvR5oaeKBSRMm63kEawrqMFP/pfaQgeNcAC0e+rK3W/P23kEJtXATUjQraq1rrIH5jezqwGzVm/IRyosHvDUtzXJJZwMm2TyYNL/SbYgN2agcN2GttHww8YvtzpPH2jWvW6b2kPAufyDNg3k8K4VGL7emjbFVjELVWhu8PzO2hleFNeibPiHp2HQQp/0Xognho2xueyA9wDwJeL2ll0mKsftNUaIsmF169hxSNcldSMvknSF+8lXKqdmMGEb27MrxJ7dZBVI6gGsqJBr83vAN4Jylf7O8lvYy0qKjfNNWANbnwagfb20q6Dp5dmVzny7Y1g2g9UsrG/8j7u5CGdurEMuqpleFdcgMp9tOHWL4OYo0JrVEfiwa/B+RG/gJgRj70R+BHE1ilrrD9ZO7BvY40jLI0/6xaTpMZl57Jd1St+D7rQvX0koVYRheTQgcvyftTqTb1dNDskh+SD5Ge6TBsFW9oUDT4PUDSe4HDSbl6NyUtyz+N9ACrb0j6DOnh6Oak3K+rkEJCV47fr4YyLgFfJ325rifpeFLkzU/VKKdl2rCwwQ+SFhaFgkKYhk2bCNMQyol5+D1A0vXA9qSl89vkYzfZ/usJrVjD8u+5DXBt4fe8seqqSjWYcSmX9wrSl2trZXIn2cL+lXSndg7pTuEAYJHt99ctsx91I0xDGFv08HvDU06JuIFnQyv04zfx0zlgVmv4ZPWa5WxHQxmXAGzfTsqm1kRZR+cHuK/Ph2bb7rvhuU7lIbjH6DAUdagmGvzecLmkVoiF3Um3uj8Z45pJJYfCvTjP0pmSh7EOBU6vUdzNpKxePfkAM8/IqRufP4SuiSGdHpAbw78nZakSKaTut5rqwfYKSdcCH6fwe9qeV+H6YsalmaQsV51mXGqEUsJxk4N/Fd9iAhOOh1AUPfwJJmklUmTMLanX251MrgQetV13Lnk3Mi41wvazC+UkzWT5kM4VtqumqwyhK6LBn2C2hyTdIOllAxAwahfgCEmtULgAlH1o23TGpW6Q9AHS6t0LSV9E35d0eq8FjQuDKYZ0eoCk/yAlubiaFRvCCRui6IaRAsLZ/m3J65/NuATcVXhrTeDXtt/dcSU7lKcYvsb2n/L+6sCVEd899ILo4feGNVgx3eGED1F0Q9mGfRRnkyIp9vJUPrFi0vJlLI//H8KEiga/NzyvV4coeskkmcr3HeAqSa2pmPsA35646oSwXAzpTKDJMEQRqssx/l9H6tlfYfu6Ca5SCEA0+BMqVhuGEMZTNPghhDAg+i2ZQgghhBFEgx9CCAMiGvwQQhgQ0eCHEMKAiAY/hBAGxP8H5QN4vvjv/hwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualise\n",
    "sb.heatmap(df.isnull())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daf436e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f5b6529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "164   38    1   2       138   175    0        1      173      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "164      2   4     2       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79d8e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To delete duplicate\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f660ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0ffe14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    164\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if Data is unbalanced\n",
    "df['target'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fb8937f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAK6UlEQVR4nO3df+ztBV3H8ddbL0igBu7e1ZCutzlloyQcd2gum7C1UU1hoi6S4cyF5nSrTZbNppSjtaQ5Z/QHW4C0hVMyf7BZrVZRlpN7zR+gsozEWNYNKRFKEXn3x/fct9/u7r2cAed7uPc+Htt395zP55zzfX+37/0+9zmfH6e6OwCQJE9a9wAAPHGIAgBDFAAYogDAEAUAxrZ1D/BYbN++vXft2rXuMQCOKHv37r2nu3ccbN0RHYVdu3Zlz5496x4D4IhSVXcdap23jwAYogDAEAUAhigAMEQBgCEKAIyVRaGqrq2qfVV12wHL31xVd1TV7VX1Owes21lV91fVW1Y1FwCHtsotheuTnL95QVWdm+SCJGd2948kueqA57w7ycdXOBMAh7Gyk9e6+5aq2nXA4l9K8tvd/e3FY/btX1FVFya5M8kDq5oJgMPb6jOan5vkxVV1ZZJvJXlLd99aVScl+dUkP5XksG8dVdVlSS5Lkp07d654XFifr/7m89Y9Ak9AO9/++ZW+/lbvaN6W5JQkL0xyeZIPVFUl+Y0k7+7u+x/pBbr7mu7e3d27d+w46KU7AHiUtnpL4e4kH+qNzwD9VFU9nGR7khckecVix/PJSR6uqm919+9t8XwAx7StjsKHk5yX5K+r6rlJjk9yT3e/eP8DquqKJPcLAsDWW1kUqurGJC9Jsr2q7k7yjiTXJrl2cZjqg0les9hqAOAJYJVHH118iFWXPMLzrnj8pwFgGc5oBmCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgLGyKFTVtVW1r6pu27TsnVX1uar6TFX9eVWdulh+XFW9r6o+X1VfrKpfW9VcABzaKrcUrk9y/gHL3tXdZ3b3WUluTvL2xfJXJnlKdz8vydlJXl9Vu1Y4GwAHsbIodPctSe49YNl9m+6elKT3r0pyUlVtS/J9SR5MsvmxAGyBbVv9DavqyiSXJvlGknMXi29KckGSryU5McmvdPe9B38FAFZly6PQ3W9L8rbFfoM3JXlHknOSfDfJqUlOSfK3VfUX3X3ngc+vqsuSXJYkO3fufMzznH35DY/5NTj67H3XpeseAdZinUcf/VGSixa3fz7Jn3b3d7p7X5JPJNl9sCd19zXdvbu7d+/YsWOLRgU4NmxpFKrqOZvuvizJlxa3v5rkvNpwUpIXbloHwBZZ2dtHVXVjkpck2V5Vd2fjbaKfqarTkzyc5K4kb1g8/Ook1yW5LUklua67P7eq2QA4uJVFobsvPsjiPzjEY+/PxmGpAKyRM5oBGKIAwBAFAIYoADBEAYAhCgAMUQBgiAIAQxQAGKIAwBAFAIYoADBEAYAhCgAMUQBgiAIAQxQAGKIAwBAFAIYoADBEAYAhCgAMUQBgiAIAQxQAGKIAwBAFAIYoADBEAYAhCgAMUQBgiAIAQxQAGKIAwBAFAIYoADBEAYAhCgAMUQBgiAIAQxQAGKIAwBAFAIYoADBEAYAhCgAMUQBgiAIAQxQAGEtFoar+cpllABzZth1uZVWdkOTEJNur6pQktVj19CSnrng2ALbYYaOQ5PVJfjkbAdib70XhviRXr24sANbhsFHo7vckeU9Vvbm737tFMwGwJo+0pZAk6e73VtWLkuza/JzuvmFFcwGwBktFoar+MMmzk3wmyXcXizuJKAAcRZaKQpLdSc7o7l7lMACs17LnKdyW5AdXOQgA67fslsL2JF+oqk8l+fb+hd39spVMBcBaLBuFK1Y5BABPDMseffQ3qx4EgPVb9uijb2bjaKMkOT7JcUke6O6nr2owALbeslsKT9t8v6ouTHLOKgYCYH0e1VVSu/vDSc57fEcBYN2Wffvo5ZvuPikb5y04ZwHgKLPs0Ucv3XT7oSRfSXLB4z4NAGu17D6F1656EADWb9kP2Tmtqv6kqvZV1X9U1R9X1WmrHg6ArbXsjubrknw0G5+r8MwkH1ssA+AosmwUdnT3dd390OLr+iQ7VjgXAGuwbBTuqapLqurJi69Lknx9lYMBsPWWjcIvJHlVkn9P8rUkr0hi5zPAUWbZQ1LfmeQ13f1fSVJVz0hyVTZiAcBRYtkthTP3ByFJuvveJM9fzUgArMuyUXhSVZ2y/85iS2HZrQwAjhDL/mH/3SR/X1U3ZePyFq9KcuXKpgJgLZY9o/mGqtqTjYvgVZKXd/cXVjoZAFtu6beAFhEQAoCj2KO6dDYARydRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAYogDAEAUAhigAMEQBgCEKAAxRAGCIAgBDFAAY1d3rnuFRq6r/THLXuuc4imxPcs+6h4CD8Lv5+HpWd+842IojOgo8vqpqT3fvXvcccCC/m1vH20cADFEAYIgCm12z7gHgEPxubhH7FAAYthQAGKIAwBAFUlXnV9UdVfXlqnrruueB/arq2qraV1W3rXuWY4UoHOOq6slJrk7y00nOSHJxVZ2x3qlgXJ/k/HUPcSwRBc5J8uXuvrO7H0zy/iQXrHkmSJJ09y1J7l33HMcSUeCZSf510/27F8uAY5AoUAdZ5jhlOEaJAncn+aFN909L8m9rmgVYM1Hg1iTPqaofrqrjk/xcko+ueSZgTUThGNfdDyV5U5I/S/LFJB/o7tvXOxVsqKobk/xDktOr6u6qet26ZzraucwFAMOWAgBDFAAYogDAEAUAhigAMEQBDqOqTq6qN27B97nQhQh5IhAFOLyTkywdhdrwaP5fXZiNq9TCWjlPAQ6jqvZfNfaOJH+V5MwkpyQ5Lsmvd/dHqmpXko8v1v94Nv7AX5rk1dm42OA9SfZ291VV9exsXKp8R5L/SfKLSZ6R5OYk31h8XdTd/7xFPyL8P9vWPQA8wb01yY9291lVtS3Jid19X1VtT/LJqtp/SZDTk7y2u99YVbuTXJTk+dn4P/bpJHsXj7smyRu6+5+q6gVJfr+7z1u8zs3dfdNW/nBwIFGA5VWS36qqn0zycDYuMf4Di3V3dfcnF7d/IslHuvt/k6SqPrb496lJXpTkg1VzcdqnbNHssBRRgOW9Ohtv+5zd3d+pqq8kOWGx7oFNjzvY5ciTjX14/93dZ61sQniM7GiGw/tmkqctbn9/kn2LIJyb5FmHeM7fJXlpVZ2w2Dr42STp7vuS/EtVvTKZndI/dpDvA2sjCnAY3f31JJ9YfHD8WUl2V9WebGw1fOkQz7k1G5cf/2ySDyXZk40dyFk873VV9dkkt+d7H336/iSXV9U/LnZGw1o4+ghWoKqe2t33V9WJSW5Jcll3f3rdc8EjsU8BVuOaxcloJyR5nyBwpLClAMCwTwGAIQoADFEAYIgCAEMUABj/B2fnJCAEKpU0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visulisation if data is unbalanced\n",
    "sb.countplot(data=df,x='target')\n",
    "f=df['target'].value_counts()\n",
    "plt.yticks(f)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "463ae04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select input and output\n",
    "X=df.drop(\"target\",axis=1)\n",
    "Y=df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "268a4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6e3fbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((211, 13), (91, 13))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape of X_train,X_test\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5540bb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((211,), (91,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape of Y_train,Y_test\n",
    "Y_train.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0cda0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply scaling on input column \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f64dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create user defined function\n",
    "def create_model(model):\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_pred=model.predict(X_test)\n",
    "    print(classification_report(Y_test,Y_pred))\n",
    "    print(confusion_matrix(Y_test,Y_pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c09c6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import classification_report and confusion_matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6ca0ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78        38\n",
      "           1       0.85      0.83      0.84        53\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.81      0.81        91\n",
      "weighted avg       0.81      0.81      0.81        91\n",
      "\n",
      "[[30  8]\n",
      " [ 9 44]]\n"
     ]
    }
   ],
   "source": [
    "#Train the model with LogisticsRegression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(random_state=1)\n",
    "lr=create_model(lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c44782f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.79      0.71        38\n",
      "           1       0.82      0.70      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.74      0.74      0.73        91\n",
      "weighted avg       0.75      0.74      0.74        91\n",
      "\n",
      "[[30  8]\n",
      " [16 37]]\n"
     ]
    }
   ],
   "source": [
    "#Train the model with DecisionTreeClassifier algorithm with Gini index \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier(random_state=1)\n",
    "dtc=create_model(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f224808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Max Depth: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.71      0.66        38\n",
      "           1       0.77      0.68      0.72        53\n",
      "\n",
      "    accuracy                           0.69        91\n",
      "   macro avg       0.69      0.69      0.69        91\n",
      "weighted avg       0.70      0.69      0.69        91\n",
      "\n",
      "[[27 11]\n",
      " [17 36]]\n",
      "Max Depth: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        38\n",
      "           1       0.77      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[26 12]\n",
      " [12 41]]\n",
      "Max Depth: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67        38\n",
      "           1       0.76      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.72      0.73      0.72        91\n",
      "\n",
      "[[25 13]\n",
      " [12 41]]\n",
      "Max Depth: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "Max Depth: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72        38\n",
      "           1       0.83      0.72      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.75      0.75      0.75        91\n",
      "weighted avg       0.76      0.75      0.75        91\n",
      "\n",
      "[[30  8]\n",
      " [15 38]]\n",
      "Max Depth: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "Max Depth: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68        38\n",
      "           1       0.80      0.62      0.70        53\n",
      "\n",
      "    accuracy                           0.69        91\n",
      "   macro avg       0.70      0.71      0.69        91\n",
      "weighted avg       0.72      0.69      0.69        91\n",
      "\n",
      "[[30  8]\n",
      " [20 33]]\n"
     ]
    }
   ],
   "source": [
    "#apply max_depth pruning technique on DecisionTreeClassifier with Gini index\n",
    "for i in range(1,9):\n",
    "    dtc_maxdepth=DecisionTreeClassifier(random_state=1,max_depth=i)\n",
    "    print('Max Depth:',i)\n",
    "    dtc_maxdepth=create_model(dtc_maxdepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "718076f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        38\n",
      "           1       0.77      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[26 12]\n",
      " [12 41]]\n"
     ]
    }
   ],
   "source": [
    "dtc_maxdepth=DecisionTreeClassifier(random_state=1,max_depth=3)\n",
    "dtc_maxdepth=create_model(dtc_maxdepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2868c06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_samples_leaf : 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n"
     ]
    }
   ],
   "source": [
    "#apply min_samples_leaf pruning technique on DecisionTreeClassifier with Gini index\n",
    "for i in range(45,101):\n",
    "    dtc_min_leaf=DecisionTreeClassifier(min_samples_leaf=i,random_state=1)\n",
    "    print('Min_samples_leaf :',i)\n",
    "    dtc_min_leaf=create_model(dtc_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "900b9554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n"
     ]
    }
   ],
   "source": [
    "dtc_min_leaf=DecisionTreeClassifier(min_samples_leaf=45,random_state=1)\n",
    "dtc_min_leaf=create_model(dtc_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "520e9dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n"
     ]
    }
   ],
   "source": [
    "#Train the model with DecisionTreeClassifier algorithm with Entropy \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc2=DecisionTreeClassifier(random_state=1,criterion='entropy')\n",
    "dtc2=create_model(dtc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "645bbc2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Max Depth: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Max Depth: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75        38\n",
      "           1       0.85      0.74      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.78      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[31  7]\n",
      " [14 39]]\n",
      "Max Depth: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.71      0.67        38\n",
      "           1       0.78      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.71      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[27 11]\n",
      " [15 38]]\n",
      "Max Depth: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "Max Depth: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "Max Depth: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "Max Depth: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.74      0.67        38\n",
      "           1       0.78      0.66      0.71        53\n",
      "\n",
      "    accuracy                           0.69        91\n",
      "   macro avg       0.69      0.70      0.69        91\n",
      "weighted avg       0.71      0.69      0.69        91\n",
      "\n",
      "[[28 10]\n",
      " [18 35]]\n"
     ]
    }
   ],
   "source": [
    "#apply max_depth pruning technique on DecisionTreeClassifier with Entropy\n",
    "for i in range(1,9):\n",
    "    dtc_maxdepth=DecisionTreeClassifier(random_state=1,max_depth=i,criterion='entropy')\n",
    "    print('Max Depth:',i)\n",
    "    dtc_maxdepth=create_model(dtc_maxdepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3961646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n"
     ]
    }
   ],
   "source": [
    "dtc_maxdepth=DecisionTreeClassifier(random_state=1,max_depth=6,criterion='entropy')\n",
    "dtc_maxdepth=create_model(dtc_maxdepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a12dd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_samples_leaf : 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "Min_samples_leaf : 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n"
     ]
    }
   ],
   "source": [
    "#apply min_samples_leaf pruning technique on DecisionTreeClassifier with Gini index\n",
    "for i in range(45,101):\n",
    "    dtc_min_leaf=DecisionTreeClassifier(min_samples_leaf=i,random_state=1,criterion='entropy')\n",
    "    print('Min_samples_leaf :',i)\n",
    "    dtc_min_leaf=create_model(dtc_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5479759f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n"
     ]
    }
   ],
   "source": [
    "dtc_min_leaf=DecisionTreeClassifier(min_samples_leaf=45,random_state=1,criterion='entropy')\n",
    "dtc_min_leaf=create_model(dtc_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81d52411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tree: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68        38\n",
      "           1       0.80      0.66      0.72        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.71      0.71      0.70        91\n",
      "weighted avg       0.72      0.70      0.71        91\n",
      "\n",
      "[[29  9]\n",
      " [18 35]]\n",
      "No. of tree: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of tree: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No. of tree: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of tree: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No. of tree: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No. of tree: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No. of tree: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No. of tree: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No. of tree: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No. of tree: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No. of tree: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.76      0.71        38\n",
      "           1       0.81      0.72      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.75      0.74      0.74        91\n",
      "\n",
      "[[29  9]\n",
      " [15 38]]\n",
      "No. of tree: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No. of tree: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No. of tree: 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of tree: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of tree: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of tree: 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of tree: 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No. of tree: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No. of tree: 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No. of tree: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No. of tree: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75        38\n",
      "           1       0.85      0.74      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.78      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[31  7]\n",
      " [14 39]]\n",
      "No. of tree: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No. of tree: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No. of tree: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76        38\n",
      "           1       0.85      0.75      0.80        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.78      0.79      0.78        91\n",
      "weighted avg       0.79      0.78      0.78        91\n",
      "\n",
      "[[31  7]\n",
      " [13 40]]\n",
      "No. of tree: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of tree: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of tree: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73        38\n",
      "           1       0.83      0.74      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.76      0.76        91\n",
      "\n",
      "[[30  8]\n",
      " [14 39]]\n",
      "No. of tree: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73        38\n",
      "           1       0.83      0.74      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.76      0.76        91\n",
      "\n",
      "[[30  8]\n",
      " [14 39]]\n",
      "No. of tree: 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72        38\n",
      "           1       0.83      0.72      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.75      0.75      0.75        91\n",
      "weighted avg       0.76      0.75      0.75        91\n",
      "\n",
      "[[30  8]\n",
      " [15 38]]\n",
      "No. of tree: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No. of tree: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of tree: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of tree: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of tree: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of tree: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76        38\n",
      "           1       0.85      0.75      0.80        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.78      0.79      0.78        91\n",
      "weighted avg       0.79      0.78      0.78        91\n",
      "\n",
      "[[31  7]\n",
      " [13 40]]\n",
      "No. of tree: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of tree: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of tree: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of tree: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of tree: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n",
      "No. of tree: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No. of tree: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n",
      "No. of tree: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n",
      "No. of tree: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No. of tree: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of tree: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No. of tree: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n"
     ]
    }
   ],
   "source": [
    "#train the model with RandomForestClassifier Algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for i in range(10,101):\n",
    "    rfc=RandomForestClassifier(n_estimators=i,random_state=1)\n",
    "    print('No. of tree:',i)\n",
    "    rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a11afaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n"
     ]
    }
   ],
   "source": [
    "rfc=RandomForestClassifier(n_estimators=81,random_state=1)\n",
    "rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "badeccee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth : 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74        38\n",
      "           1       0.81      0.81      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[28 10]\n",
      " [10 43]]\n",
      "Max depth : 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76        38\n",
      "           1       0.82      0.85      0.83        53\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.80      0.79      0.80        91\n",
      "weighted avg       0.80      0.80      0.80        91\n",
      "\n",
      "[[28 10]\n",
      " [ 8 45]]\n",
      "Max depth : 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77        38\n",
      "           1       0.83      0.85      0.84        53\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.81      0.81        91\n",
      "weighted avg       0.81      0.81      0.81        91\n",
      "\n",
      "[[29  9]\n",
      " [ 8 45]]\n",
      "Max depth : 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        38\n",
      "           1       0.83      0.81      0.82        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.79      0.79      0.79        91\n",
      "\n",
      "[[29  9]\n",
      " [10 43]]\n",
      "Max depth : 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76        38\n",
      "           1       0.84      0.79      0.82        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.79      0.79      0.79        91\n",
      "\n",
      "[[30  8]\n",
      " [11 42]]\n",
      "Max depth : 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "Max depth : 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76        38\n",
      "           1       0.85      0.75      0.80        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.78      0.79      0.78        91\n",
      "weighted avg       0.79      0.78      0.78        91\n",
      "\n",
      "[[31  7]\n",
      " [13 40]]\n",
      "Max depth : 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76        38\n",
      "           1       0.85      0.75      0.80        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.78      0.79      0.78        91\n",
      "weighted avg       0.79      0.78      0.78        91\n",
      "\n",
      "[[31  7]\n",
      " [13 40]]\n"
     ]
    }
   ],
   "source": [
    "#Apply max_depth pruning on RandomForestClassifier Algorithm\n",
    "for i in range(1,9):\n",
    "    rfc_max_depth=RandomForestClassifier(n_estimators=81,random_state=1,max_depth=i)\n",
    "    print('Max depth :',i)\n",
    "    rfc_max_depth=create_model(rfc_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b34049a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77        38\n",
      "           1       0.83      0.85      0.84        53\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.81      0.81        91\n",
      "weighted avg       0.81      0.81      0.81        91\n",
      "\n",
      "[[29  9]\n",
      " [ 8 45]]\n"
     ]
    }
   ],
   "source": [
    "rfc_max_depth=RandomForestClassifier(n_estimators=81,random_state=1,max_depth=3)\n",
    "rfc_max_depth=create_model(rfc_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae46502f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_samples_leaf : 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        38\n",
      "           1       0.83      0.81      0.82        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.79      0.79      0.79        91\n",
      "\n",
      "[[29  9]\n",
      " [10 43]]\n",
      "Min_samples_leaf : 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        38\n",
      "           1       0.83      0.81      0.82        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.79      0.79      0.79        91\n",
      "\n",
      "[[29  9]\n",
      " [10 43]]\n",
      "Min_samples_leaf : 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        38\n",
      "           1       0.83      0.81      0.82        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.79      0.79      0.79        91\n",
      "\n",
      "[[29  9]\n",
      " [10 43]]\n",
      "Min_samples_leaf : 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        38\n",
      "           1       0.83      0.81      0.82        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.79      0.79      0.79        91\n",
      "\n",
      "[[29  9]\n",
      " [10 43]]\n",
      "Min_samples_leaf : 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        38\n",
      "           1       0.83      0.81      0.82        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.79      0.79      0.79        91\n",
      "\n",
      "[[29  9]\n",
      " [10 43]]\n",
      "Min_samples_leaf : 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        38\n",
      "           1       0.83      0.81      0.82        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.79      0.79      0.79        91\n",
      "\n",
      "[[29  9]\n",
      " [10 43]]\n",
      "Min_samples_leaf : 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        38\n",
      "           1       0.83      0.81      0.82        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.79      0.79      0.79        91\n",
      "\n",
      "[[29  9]\n",
      " [10 43]]\n",
      "Min_samples_leaf : 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74        38\n",
      "           1       0.81      0.81      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[28 10]\n",
      " [10 43]]\n",
      "Min_samples_leaf : 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "Min_samples_leaf : 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "Min_samples_leaf : 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71        38\n",
      "           1       0.79      0.79      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.75      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[27 11]\n",
      " [11 42]]\n",
      "Min_samples_leaf : 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72        38\n",
      "           1       0.80      0.81      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[27 11]\n",
      " [10 43]]\n",
      "Min_samples_leaf : 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72        38\n",
      "           1       0.80      0.81      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[27 11]\n",
      " [10 43]]\n",
      "Min_samples_leaf : 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70        38\n",
      "           1       0.78      0.81      0.80        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.75      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[26 12]\n",
      " [10 43]]\n",
      "Min_samples_leaf : 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72        38\n",
      "           1       0.80      0.81      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[27 11]\n",
      " [10 43]]\n",
      "Min_samples_leaf : 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70        38\n",
      "           1       0.79      0.77      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.74      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[27 11]\n",
      " [12 41]]\n",
      "Min_samples_leaf : 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        38\n",
      "           1       0.77      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[26 12]\n",
      " [12 41]]\n",
      "Min_samples_leaf : 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        38\n",
      "           1       0.77      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[26 12]\n",
      " [12 41]]\n",
      "Min_samples_leaf : 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        38\n",
      "           1       0.77      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[26 12]\n",
      " [12 41]]\n",
      "Min_samples_leaf : 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        38\n",
      "           1       0.77      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[26 12]\n",
      " [12 41]]\n",
      "Min_samples_leaf : 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "Min_samples_leaf : 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67        38\n",
      "           1       0.76      0.77      0.77        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.72      0.73      0.72        91\n",
      "\n",
      "[[25 13]\n",
      " [12 41]]\n",
      "Min_samples_leaf : 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68        38\n",
      "           1       0.77      0.81      0.79        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.73      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[25 13]\n",
      " [10 43]]\n",
      "Min_samples_leaf : 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.47      0.56        38\n",
      "           1       0.69      0.85      0.76        53\n",
      "\n",
      "    accuracy                           0.69        91\n",
      "   macro avg       0.69      0.66      0.66        91\n",
      "weighted avg       0.69      0.69      0.68        91\n",
      "\n",
      "[[18 20]\n",
      " [ 8 45]]\n",
      "Min_samples_leaf : 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n",
      "Min_samples_leaf : 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        38\n",
      "           1       0.58      1.00      0.74        53\n",
      "\n",
      "    accuracy                           0.58        91\n",
      "   macro avg       0.29      0.50      0.37        91\n",
      "weighted avg       0.34      0.58      0.43        91\n",
      "\n",
      "[[ 0 38]\n",
      " [ 0 53]]\n"
     ]
    }
   ],
   "source": [
    "#Apply min_samples_leaf pruning on RandomForestClassifier Algorithm\n",
    "for i in range(45,101):\n",
    "    rfc_min_leaf=RandomForestClassifier(n_estimators=81,random_state=1,min_samples_leaf=i)\n",
    "    print('Min_samples_leaf :',i)\n",
    "    rfc_min_leaf=create_model(rfc_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09e01076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        38\n",
      "           1       0.83      0.81      0.82        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.79      0.79      0.79        91\n",
      "\n",
      "[[29  9]\n",
      " [10 43]]\n"
     ]
    }
   ],
   "source": [
    "rfc_min_leaf=RandomForestClassifier(n_estimators=81,random_state=1,min_samples_leaf=45)\n",
    "rfc_min_leaf=create_model(rfc_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3453b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Decision stumps: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66        38\n",
      "           1       0.76      0.72      0.74        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.70      0.70        91\n",
      "weighted avg       0.71      0.70      0.70        91\n",
      "\n",
      "[[26 12]\n",
      " [15 38]]\n",
      "No of Decision stumps: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71        38\n",
      "           1       0.88      0.55      0.67        53\n",
      "\n",
      "    accuracy                           0.69        91\n",
      "   macro avg       0.73      0.72      0.69        91\n",
      "weighted avg       0.76      0.69      0.69        91\n",
      "\n",
      "[[34  4]\n",
      " [24 29]]\n",
      "No of Decision stumps: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        38\n",
      "           1       0.82      0.79      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.78      0.78        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[29  9]\n",
      " [11 42]]\n",
      "No of Decision stumps: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71        38\n",
      "           1       0.79      0.79      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.75      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[27 11]\n",
      " [11 42]]\n",
      "No of Decision stumps: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69        38\n",
      "           1       0.78      0.79      0.79        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.74      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[26 12]\n",
      " [11 42]]\n",
      "No of Decision stumps: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72        38\n",
      "           1       0.80      0.81      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[27 11]\n",
      " [10 43]]\n",
      "No of Decision stumps: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70        38\n",
      "           1       0.79      0.77      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.74      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[27 11]\n",
      " [12 41]]\n",
      "No of Decision stumps: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73        38\n",
      "           1       0.81      0.79      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[28 10]\n",
      " [11 42]]\n",
      "No of Decision stumps: 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        38\n",
      "           1       0.83      0.75      0.79        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.77      0.77        91\n",
      "\n",
      "[[30  8]\n",
      " [13 40]]\n",
      "No of Decision stumps: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75        38\n",
      "           1       0.84      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.78      0.78      0.78        91\n",
      "weighted avg       0.79      0.78      0.78        91\n",
      "\n",
      "[[30  8]\n",
      " [12 41]]\n",
      "No of Decision stumps: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78        38\n",
      "           1       0.86      0.79      0.82        53\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.80      0.80      0.80        91\n",
      "weighted avg       0.81      0.80      0.80        91\n",
      "\n",
      "[[31  7]\n",
      " [11 42]]\n",
      "No of Decision stumps: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77        38\n",
      "           1       0.85      0.77      0.81        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.80      0.79      0.79        91\n",
      "\n",
      "[[31  7]\n",
      " [12 41]]\n",
      "No of Decision stumps: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77        38\n",
      "           1       0.85      0.77      0.81        53\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.79      0.79      0.79        91\n",
      "weighted avg       0.80      0.79      0.79        91\n",
      "\n",
      "[[31  7]\n",
      " [12 41]]\n",
      "No of Decision stumps: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80        38\n",
      "           1       0.88      0.81      0.84        53\n",
      "\n",
      "    accuracy                           0.82        91\n",
      "   macro avg       0.82      0.83      0.82        91\n",
      "weighted avg       0.83      0.82      0.83        91\n",
      "\n",
      "[[32  6]\n",
      " [10 43]]\n",
      "No of Decision stumps: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79        38\n",
      "           1       0.88      0.79      0.83        53\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.82      0.81        91\n",
      "weighted avg       0.82      0.81      0.81        91\n",
      "\n",
      "[[32  6]\n",
      " [11 42]]\n",
      "No of Decision stumps: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.78        38\n",
      "           1       0.86      0.81      0.83        53\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.81      0.81        91\n",
      "weighted avg       0.82      0.81      0.81        91\n",
      "\n",
      "[[31  7]\n",
      " [10 43]]\n",
      "No of Decision stumps: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.78        38\n",
      "           1       0.86      0.81      0.83        53\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.81      0.81        91\n",
      "weighted avg       0.82      0.81      0.81        91\n",
      "\n",
      "[[31  7]\n",
      " [10 43]]\n",
      "No of Decision stumps: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79        38\n",
      "           1       0.88      0.79      0.83        53\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.82      0.81        91\n",
      "weighted avg       0.82      0.81      0.81        91\n",
      "\n",
      "[[32  6]\n",
      " [11 42]]\n",
      "No of Decision stumps: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.78        38\n",
      "           1       0.86      0.81      0.83        53\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.81      0.81        91\n",
      "weighted avg       0.82      0.81      0.81        91\n",
      "\n",
      "[[31  7]\n",
      " [10 43]]\n"
     ]
    }
   ],
   "source": [
    "#Apply ADABoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "for i in range(1,20):\n",
    "    abc=AdaBoostClassifier(n_estimators=i,random_state=1)\n",
    "    print('No of Decision stumps:',i)\n",
    "    abc=create_model(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abba4829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80        38\n",
      "           1       0.88      0.81      0.84        53\n",
      "\n",
      "    accuracy                           0.82        91\n",
      "   macro avg       0.82      0.83      0.82        91\n",
      "weighted avg       0.83      0.82      0.83        91\n",
      "\n",
      "[[32  6]\n",
      " [10 43]]\n"
     ]
    }
   ],
   "source": [
    "abc=AdaBoostClassifier(n_estimators=14,random_state=1)\n",
    "abc=create_model(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad379717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of decision tree: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73        38\n",
      "           1       0.81      0.79      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[28 10]\n",
      " [11 42]]\n",
      "No of decision tree: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74        38\n",
      "           1       0.81      0.81      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[28 10]\n",
      " [10 43]]\n",
      "No of decision tree: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No of decision tree: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        38\n",
      "           1       0.82      0.79      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.78      0.78        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[29  9]\n",
      " [11 42]]\n",
      "No of decision tree: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n",
      "No of decision tree: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of decision tree: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of decision tree: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of decision tree: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of decision tree: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of decision tree: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of decision tree: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n",
      "No of decision tree: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70        38\n",
      "           1       0.79      0.77      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.74      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[27 11]\n",
      " [12 41]]\n",
      "No of decision tree: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No of decision tree: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No of decision tree: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70        38\n",
      "           1       0.79      0.77      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.74      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[27 11]\n",
      " [12 41]]\n",
      "No of decision tree: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of decision tree: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of decision tree: 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of decision tree: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of decision tree: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of decision tree: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of decision tree: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of decision tree: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of decision tree: 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        38\n",
      "           1       0.82      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[29  9]\n",
      " [13 40]]\n",
      "No of decision tree: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of decision tree: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.76      0.71        38\n",
      "           1       0.81      0.72      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.75      0.74      0.74        91\n",
      "\n",
      "[[29  9]\n",
      " [15 38]]\n",
      "No of decision tree: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of decision tree: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.76      0.71        38\n",
      "           1       0.81      0.72      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.75      0.74      0.74        91\n",
      "\n",
      "[[29  9]\n",
      " [15 38]]\n",
      "No of decision tree: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.76      0.71        38\n",
      "           1       0.81      0.72      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.75      0.74      0.74        91\n",
      "\n",
      "[[29  9]\n",
      " [15 38]]\n",
      "No of decision tree: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of decision tree: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of decision tree: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of decision tree: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of decision tree: 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of decision tree: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.67        38\n",
      "           1       0.78      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.71      0.70        91\n",
      "weighted avg       0.72      0.70      0.71        91\n",
      "\n",
      "[[28 10]\n",
      " [17 36]]\n",
      "No of decision tree: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.67        38\n",
      "           1       0.78      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.71      0.70        91\n",
      "weighted avg       0.72      0.70      0.71        91\n",
      "\n",
      "[[28 10]\n",
      " [17 36]]\n",
      "No of decision tree: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.67        38\n",
      "           1       0.78      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.70        91\n",
      "   macro avg       0.70      0.71      0.70        91\n",
      "weighted avg       0.72      0.70      0.71        91\n",
      "\n",
      "[[28 10]\n",
      " [17 36]]\n",
      "No of decision tree: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of decision tree: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of decision tree: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of decision tree: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of decision tree: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of decision tree: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of decision tree: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of decision tree: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        38\n",
      "           1       0.79      0.70      0.74        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.72      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[28 10]\n",
      " [16 37]]\n",
      "No of decision tree: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of decision tree: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of decision tree: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        38\n",
      "           1       0.80      0.68      0.73        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.72      0.72      0.71        91\n",
      "weighted avg       0.73      0.71      0.72        91\n",
      "\n",
      "[[29  9]\n",
      " [17 36]]\n",
      "No of decision tree: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of decision tree: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of decision tree: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n",
      "No of decision tree: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70        38\n",
      "           1       0.80      0.70      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.74      0.73      0.73        91\n",
      "\n",
      "[[29  9]\n",
      " [16 37]]\n"
     ]
    }
   ],
   "source": [
    "#Apply GradientBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "for i in range(10,101):\n",
    "    gbc=GradientBoostingClassifier(n_estimators=i,random_state=1)\n",
    "    print('No of decision tree:',i)\n",
    "    gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d86bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74        38\n",
      "           1       0.81      0.81      0.81        53\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.78      0.78      0.78        91\n",
      "\n",
      "[[28 10]\n",
      " [10 43]]\n"
     ]
    }
   ],
   "source": [
    "gbc=GradientBoostingClassifier(n_estimators=11,random_state=1)\n",
    "gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "09c6fcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of decision tree: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n",
      "No of decision tree: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.72        38\n",
      "           1       0.81      0.74      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[29  9]\n",
      " [14 39]]\n",
      "No of decision tree: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72        38\n",
      "           1       0.83      0.72      0.77        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.75      0.75      0.75        91\n",
      "weighted avg       0.76      0.75      0.75        91\n",
      "\n",
      "[[30  8]\n",
      " [15 38]]\n",
      "No of decision tree: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of decision tree: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of decision tree: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of decision tree: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of decision tree: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No of decision tree: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        38\n",
      "           1       0.80      0.77      0.79        53\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.75      0.76      0.75        91\n",
      "weighted avg       0.76      0.76      0.76        91\n",
      "\n",
      "[[28 10]\n",
      " [12 41]]\n",
      "No of decision tree: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of decision tree: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of decision tree: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of decision tree: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of decision tree: 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of decision tree: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of decision tree: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69        38\n",
      "           1       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[27 11]\n",
      " [13 40]]\n",
      "No of decision tree: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of decision tree: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of decision tree: 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        38\n",
      "           1       0.80      0.75      0.78        53\n",
      "\n",
      "    accuracy                           0.75        91\n",
      "   macro avg       0.74      0.75      0.74        91\n",
      "weighted avg       0.75      0.75      0.75        91\n",
      "\n",
      "[[28 10]\n",
      " [13 40]]\n",
      "No of decision tree: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of decision tree: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28 10]\n",
      " [14 39]]\n",
      "No of decision tree: 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of decision tree: 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of decision tree: 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of decision tree: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of decision tree: 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of decision tree: 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of decision tree: 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of decision tree: 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of decision tree: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of decision tree: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of decision tree: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of decision tree: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        38\n",
      "           1       0.79      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.73      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[28 10]\n",
      " [15 38]]\n",
      "No of decision tree: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.71      0.67        38\n",
      "           1       0.78      0.72      0.75        53\n",
      "\n",
      "    accuracy                           0.71        91\n",
      "   macro avg       0.71      0.71      0.71        91\n",
      "weighted avg       0.72      0.71      0.72        91\n",
      "\n",
      "[[27 11]\n",
      " [15 38]]\n",
      "No of decision tree: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        38\n",
      "           1       0.80      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.74        91\n",
      "   macro avg       0.73      0.74      0.73        91\n",
      "weighted avg       0.74      0.74      0.74        91\n",
      "\n",
      "[[28 10]\n",
      " [14 39]]\n",
      "No of decision tree: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n",
      "No of decision tree: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        38\n",
      "           1       0.78      0.74      0.76        53\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.72      0.72      0.72        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "[[27 11]\n",
      " [14 39]]\n"
     ]
    }
   ],
   "source": [
    "#Apply XtremeGradientBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "for i in range(10,101):\n",
    "    xgbc=XGBClassifier(n_estimators=i,reg_alpha=1,random_state=1,)\n",
    "    print('No of decision tree:',i)\n",
    "    xgbc=create_model(xgbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cfd10247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        38\n",
      "           1       0.82      0.77      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[29  9]\n",
      " [12 41]]\n"
     ]
    }
   ],
   "source": [
    "xgbc=XGBClassifier(n_estimators=10,reg_alpha=1,random_state=1)\n",
    "xgbc=create_model(xgbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "82dc53e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76        38\n",
      "           1       0.83      0.83      0.83        53\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.80      0.80      0.80        91\n",
      "weighted avg       0.80      0.80      0.80        91\n",
      "\n",
      "[[29  9]\n",
      " [ 9 44]]\n"
     ]
    }
   ],
   "source": [
    "#Apply Support Vector Machine algorithm with hard margin\n",
    "from sklearn.svm import LinearSVC\n",
    "svc=LinearSVC(random_state=1)\n",
    "svc=create_model(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba25fbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76        38\n",
      "           1       0.83      0.83      0.83        53\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.80      0.80      0.80        91\n",
      "weighted avg       0.80      0.80      0.80        91\n",
      "\n",
      "[[29  9]\n",
      " [ 9 44]]\n"
     ]
    }
   ],
   "source": [
    "#Apply Support Vector Machine algorithm with soft margin\n",
    "from sklearn.svm import LinearSVC\n",
    "svc=LinearSVC(random_state=1,C=0.9)\n",
    "svc=create_model(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31a914e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78        38\n",
      "           1       0.84      0.87      0.85        53\n",
      "\n",
      "    accuracy                           0.82        91\n",
      "   macro avg       0.82      0.82      0.82        91\n",
      "weighted avg       0.82      0.82      0.82        91\n",
      "\n",
      "[[29  9]\n",
      " [ 7 46]]\n"
     ]
    }
   ],
   "source": [
    "#No improvent in recall score, means data is non linear \n",
    "#Apply Support Vector Machine algorithm for non linear data with polynomial kernel function\n",
    "from sklearn.svm import SVC\n",
    "poly_svc=SVC(random_state=1,kernel='poly')\n",
    "poly_svc=create_model(poly_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "413a93dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73        38\n",
      "           1       0.81      0.79      0.80        53\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n",
      "[[28 10]\n",
      " [11 42]]\n"
     ]
    }
   ],
   "source": [
    "#Apply Support Vector Machine algorithm for non linear data with radial basis kernel function\n",
    "r_svc=SVC(random_state=1,kernel='rbf')\n",
    "r_svc=create_model(r_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9174b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77        38\n",
      "           1       0.84      0.81      0.83        53\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.80      0.80      0.80        91\n",
      "weighted avg       0.80      0.80      0.80        91\n",
      "\n",
      "[[30  8]\n",
      " [10 43]]\n"
     ]
    }
   ],
   "source": [
    "#Apply KNN algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "knc=create_model(knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1756c58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Recall 0</th>\n",
       "      <th>Recall 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC_poly</td>\n",
       "      <td>76</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RFC_max</td>\n",
       "      <td>76</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logostic Regression</td>\n",
       "      <td>79</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RFC_min</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADA</td>\n",
       "      <td>84</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GBC</td>\n",
       "      <td>74</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN</td>\n",
       "      <td>79</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC_r</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_G_max</td>\n",
       "      <td>68</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGB</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_E_max</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_G_min</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTC_G_min</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Algorithm  Recall 0  Recall 1\n",
       "10             SVC_poly        76        87\n",
       "5               RFC_max        76        85\n",
       "0   Logostic Regression        79        83\n",
       "6               RFC_min        76        81\n",
       "7                   ADA        84        81\n",
       "8                   GBC        74        81\n",
       "12                  KNN        79        81\n",
       "11                SVC_r        74        79\n",
       "1             DTC_G_max        68        77\n",
       "9                   XGB        76        77\n",
       "3             DTC_E_max        74        75\n",
       "2             DTC_G_min        68        72\n",
       "4             DTC_G_min        68        72"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'Algorithm':['Logostic Regression','DTC_G_max','DTC_G_min','DTC_E_max','DTC_G_min','RFC_max','RFC_min','ADA','GBC','XGB',\n",
    "                   'SVC_poly','SVC_r','KNN'],\n",
    "     'Recall 0':[79,68,68,74,68,76,76,84,74,76,76,74,79],\n",
    "     'Recall 1':[83,77,72,75,72,85,81,81,81,77,87,79,81]}\n",
    "df1=pd.DataFrame(dict)\n",
    "df1.sort_values('Recall 1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baec2bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
